"""
RAG äº¤äº’å¼å¯¹è¯ç³»ç»Ÿ - main.py
æ”¯æŒä»æœ¬åœ°æ–‡ä»¶å’Œé£ä¹¦åŠ è½½æ•°æ®ï¼Œä½¿ç”¨ RAG + LLM è¿›è¡Œå¯¹è¯
"""

import logging
import os
from typing import List, Optional, Dict, Any
from pathlib import Path

from src.rag.client import RAGClient
from src.rag.llm_client import LLMClient
from src.data.loaders import LocalFileLoader, FeishuDocxLoader
from src.data.config import FeishuConfig

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


class RAGChatbot:
    """RAG å¯¹è¯æœºå™¨äºº - æ”¯æŒå¤šæ•°æ®æº"""

    def __init__(
        self,
        llm_api_key: str,
        llm_model: str = "moonshot-v1-8k",
        local_directory: Optional[str] = None,
        data_directory: Optional[str] = None,
        feishu_doc_ids: Optional[List[str]] = None,
        feishu_config: Optional[FeishuConfig] = None,
    ):
        """
        åˆå§‹åŒ– RAGChatbot

        Args:
            llm_api_key: LLM API å¯†é’¥ï¼ˆKimi APIï¼‰
            llm_model: LLM æ¨¡å‹åç§°
            local_directory: æœ¬åœ°æ–‡ä»¶ç›®å½•
            data_directory: æ•°æ®ç›®å½•ï¼ˆä¼šæ‰«ææ‰€æœ‰ .txt å’Œ .md æ–‡ä»¶ï¼‰
            feishu_doc_ids: é£ä¹¦æ–‡æ¡£ ID åˆ—è¡¨
            feishu_config: é£ä¹¦é…ç½®å¯¹è±¡
        """
        self.llm_api_key = llm_api_key
        self.llm_model = llm_model

        # åˆå§‹åŒ– RAG å®¢æˆ·ç«¯
        logger.info("åˆå§‹åŒ– RAG å®¢æˆ·ç«¯...")
        self.rag_client = RAGClient()

        # åŠ è½½æ•°æ®æº
        documents = []

        # æœ¬åœ°ç›®å½•
        if data_directory:
            logger.info(f"ä»ç›®å½•åŠ è½½æ–‡ä»¶: {data_directory}")
            loader = LocalFileLoader(directory=data_directory, file_pattern="*.{txt,md}")
            documents.extend(loader.load())

        # ç‰¹å®šæ–‡ä»¶ç›®å½•
        if local_directory:
            logger.info(f"ä»ç›®å½•åŠ è½½æ–‡ä»¶: {local_directory}")
            loader = LocalFileLoader(directory=local_directory, file_pattern="*.{txt,md}")
            documents.extend(loader.load())

        # é£ä¹¦æ–‡æ¡£
        if feishu_doc_ids:
            try:
                if feishu_config is None:
                    feishu_config = FeishuConfig.from_env()

                logger.info(f"ä»é£ä¹¦åŠ è½½ {len(feishu_doc_ids)} ä¸ªæ–‡æ¡£...")
                loader = FeishuDocxLoader(config=feishu_config, document_ids=feishu_doc_ids)
                documents.extend(loader.load())
            except Exception as e:
                logger.warning(f"é£ä¹¦åŠ è½½å¤±è´¥: {e}")

        # æ·»åŠ æ–‡æ¡£åˆ° RAG
        if documents:
            logger.info(f"æ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£åˆ°å‘é‡å­˜å‚¨...")
            for doc in documents:
                self.rag_client.add_document(
                    content=doc.content,
                    metadata={
                        "source": doc.source,
                        "title": doc.title or "Untitled",
                        "doc_id": doc.doc_id,
                    },
                    doc_id=doc.doc_id,
                )
            logger.info("âœ… æ–‡æ¡£åŠ è½½å®Œæˆ")
        else:
            logger.warning("âš ï¸  æœªåŠ è½½ä»»ä½•æ–‡æ¡£")

        # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
        if llm_api_key:
            logger.info("åˆå§‹åŒ– LLM å®¢æˆ·ç«¯...")
            self.llm_client = LLMClient(api_key=llm_api_key, model=llm_model)
        else:
            logger.warning("æœªæä¾› LLM API å¯†é’¥ï¼Œä»…æœç´¢åŠŸèƒ½å¯ç”¨")
            self.llm_client = None

        logger.info("âœ… RAGChatbot åˆå§‹åŒ–å®Œæˆ")

    def chat(self, query: str, limit: int = 3) -> str:
        """
        ç®€å•å¯¹è¯ - æœç´¢ + LLM ç”Ÿæˆ

        Args:
            query: ç”¨æˆ·é—®é¢˜
            limit: æ£€ç´¢ç»“æœæ•°é‡

        Returns:
            LLM ç”Ÿæˆçš„å›ç­”
        """
        if not self.llm_client:
            return "âŒ LLM æœªåˆå§‹åŒ–ï¼Œè¯·æä¾› API å¯†é’¥"

        # æœç´¢ç›¸å…³æ–‡æ¡£
        results = self.rag_client.search(query, limit=limit)

        if not results:
            return "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£"

        # æå–å†…å®¹
        context = [result["content"] for result in results]

        # ä½¿ç”¨ LLM ç”Ÿæˆå›ç­”
        response = self.llm_client.generate(query=query, context=context)
        return response

    def chat_with_context(self, query: str, limit: int = 3) -> Dict[str, Any]:
        """
        å¯¹è¯å¹¶è¿”å›ä¸Šä¸‹æ–‡

        Args:
            query: ç”¨æˆ·é—®é¢˜
            limit: æ£€ç´¢ç»“æœæ•°é‡

        Returns:
            åŒ…å« answer, context, query çš„å­—å…¸
        """
        if not self.llm_client:
            return {
                "answer": "âŒ LLM æœªåˆå§‹åŒ–",
                "context": [],
                "query": query,
            }

        # æœç´¢ç›¸å…³æ–‡æ¡£
        results = self.rag_client.search(query, limit=limit)

        # æå–å†…å®¹å’Œå…ƒæ•°æ®
        context = []
        if results:
            for result in results:
                context.append({
                    "content": result["content"],
                    "score": result["score"],
                    "metadata": result.get("metadata", {}),
                })

        # ç”Ÿæˆå›ç­”
        context_text = [r["content"] for r in context]
        answer = self.llm_client.generate(query=query, context=context_text) if context_text else "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£"

        return {
            "query": query,
            "answer": answer,
            "context": context,
        }

    def search_only(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """
        ä»…æœç´¢ï¼Œä¸ä½¿ç”¨ LLM

        Args:
            query: æŸ¥è¯¢
            limit: ç»“æœæ•°é‡

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        return self.rag_client.search(query, limit=limit)

    def should_exit(self, user_input: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é€€å‡º"""
        exit_commands = ["exit", "quit", "q", "bye", "goodbye", "é€€å‡º", "å†è§"]
        return user_input.lower().strip() in exit_commands

    def interactive_chat(self) -> None:
        """
        äº¤äº’å¼å¯¹è¯å¾ªç¯
        åœ¨ç»ˆç«¯è¿è¡ŒæŒç»­å¯¹è¯
        """
        print("\n" + "=" * 60)
        print("ğŸ¤– RAG æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
        print("=" * 60)
        print("è¾“å…¥ä½ çš„é—®é¢˜ï¼Œç³»ç»Ÿå°†æ ¹æ®æ–‡æ¡£å›ç­”")
        print("è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡º\n")

        while True:
            try:
                user_input = input("ä½ : ").strip()

                if not user_input:
                    continue

                if self.should_exit(user_input):
                    print("\nğŸ‘‹ å†è§ï¼")
                    break

                # å¯¹è¯
                print("\nğŸ” æœç´¢ä¸­...\n")
                response = self.chat(user_input)

                print(f"åŠ©æ‰‹: {response}\n")
                print("-" * 60 + "\n")

            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                logger.error(f"é”™è¯¯: {e}")
                print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}\n")

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        return self.rag_client.get_stats()


def main():
    """ä¸»å‡½æ•° - å¯åŠ¨äº¤äº’å¼å¯¹è¯"""
    import argparse
    from dotenv import load_dotenv

    # åŠ è½½ .env æ–‡ä»¶
    load_dotenv()

    parser = argparse.ArgumentParser(description="RAG äº¤äº’å¼å¯¹è¯ç³»ç»Ÿ")
    parser.add_argument(
        "--local-dir",
        type=str,
        help="æœ¬åœ°æ–‡ä»¶ç›®å½•",
        default=None,
    )
    parser.add_argument(
        "--data-dir",
        type=str,
        help="æ•°æ®ç›®å½•ï¼ˆä¼šæ‰«ææ‰€æœ‰ .txt å’Œ .md æ–‡ä»¶ï¼‰",
        default=os.getenv("DATA_DIRECTORY", "./docs"),
    )
    parser.add_argument(
        "--feishu-doc-ids",
        type=str,
        nargs="+",
        help="é£ä¹¦æ–‡æ¡£ ID",
        default=None,
    )
    parser.add_argument(
        "--llm-api-key",
        type=str,
        help="LLM API å¯†é’¥",
        default=None,
    )
    parser.add_argument(
        "--llm-model",
        type=str,
        help="LLM æ¨¡å‹åç§°",
        default="moonshot-v1-8k",
    )

    args = parser.parse_args()

    # è·å– API å¯†é’¥
    llm_api_key = args.llm_api_key or os.getenv("MOONSHOT_API_KEY")

    if not llm_api_key:
        logger.warning("âš ï¸  æœªæä¾› LLM API å¯†é’¥ï¼Œä»…æœç´¢åŠŸèƒ½å¯ç”¨")
        logger.info("è®¾ç½®æ–¹å¼ï¼š")
        logger.info("  1. å‘½ä»¤è¡Œ: python main.py --llm-api-key xxx")
        logger.info("  2. ç¯å¢ƒå˜é‡: export MOONSHOT_API_KEY=xxx")

    # åˆ›å»ºå¯¹è¯æœºå™¨äºº
    chatbot = RAGChatbot(
        llm_api_key=llm_api_key or "dummy_key",
        llm_model=args.llm_model,
        local_directory=args.local_dir,
        data_directory=args.data_dir,
        feishu_doc_ids=args.feishu_doc_ids,
    )

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    stats = chatbot.get_stats()
    print(f"\nğŸ“Š ç³»ç»Ÿç»Ÿè®¡: {stats}\n")

    # å¯åŠ¨äº¤äº’å¼å¯¹è¯
    chatbot.interactive_chat()


if __name__ == "__main__":
    main()
