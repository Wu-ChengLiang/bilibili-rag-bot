"""RAG + å¤šè½®å¯¹è¯æœåŠ¡ - æ•´åˆ RAGã€LLMã€å†å²ç®¡ç†"""

import logging
from typing import List, Optional, Dict, Any

from src.rag.client import RAGClient
from src.llm.factory import LLMFactory
from .conversation_manager import ConversationManager

logger = logging.getLogger(__name__)


class RAGChatService:
    """å®Œæ•´çš„ RAG + å¤šè½®å¯¹è¯ + å†å²ç®¡ç†æœåŠ¡"""

    def __init__(
        self,
        llm_provider: str,
        llm_api_key: str,
        data_directory: Optional[str] = None,
        llm_model: str = "moonshot-v1-8k",
        history_dir: str = "./history",
    ):
        """
        åˆå§‹åŒ–æœåŠ¡

        Args:
            llm_provider: LLM æä¾›è€… ("kimi", "gpt", etc.)
            llm_api_key: LLM API å¯†é’¥
            data_directory: æ•°æ®ç›®å½•ï¼ˆç”¨äº RAGï¼‰
            llm_model: LLM æ¨¡å‹åç§°
            history_dir: å†å²æ–‡ä»¶å­˜å‚¨ç›®å½•
        """
        logger.info("åˆå§‹åŒ– RAGChatService...")

        # åˆå§‹åŒ– RAG å®¢æˆ·ç«¯
        self.rag_client = RAGClient()
        if data_directory:
            self._load_documents(data_directory)

        # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
        self.llm = LLMFactory.create(
            provider=llm_provider,
            api_key=llm_api_key,
            model=llm_model,
        )

        # åˆå§‹åŒ–å†å²ç®¡ç†
        self.conversation_mgr = ConversationManager(base_dir=history_dir)

        logger.info("âœ… RAGChatService åˆå§‹åŒ–å®Œæˆ")

    def _load_documents(self, data_directory: str) -> None:
        """ä»ç›®å½•åŠ è½½æ–‡æ¡£"""
        from src.data.loaders import LocalFileLoader

        logger.info(f"ä» {data_directory} åŠ è½½æ–‡æ¡£...")

        # åŠ è½½ .txt æ–‡ä»¶
        loader_txt = LocalFileLoader(directory=data_directory, file_pattern="*.txt")
        documents_txt = loader_txt.load()

        # åŠ è½½ .md æ–‡ä»¶
        loader_md = LocalFileLoader(directory=data_directory, file_pattern="*.md")
        documents_md = loader_md.load()

        documents = documents_txt + documents_md

        if documents:
            for doc in documents:
                self.rag_client.add_document(
                    content=doc.content,
                    metadata={
                        "source": doc.source,
                        "title": doc.title or "Untitled",
                        "doc_id": doc.doc_id,
                    },
                    doc_id=doc.doc_id,
                )
            logger.info(f"âœ… åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£")
        else:
            logger.warning("âš ï¸  æœªåŠ è½½ä»»ä½•æ–‡æ¡£")

    def debug_search(self, query: str, limit: int = 5) -> None:
        """è°ƒè¯•æœç´¢è¿‡ç¨‹ - æ‰“å°è¯¦ç»†çš„æœç´¢ä¿¡æ¯"""
        print("\n" + "=" * 80)
        print(f"ğŸ” DEBUG: æœç´¢è¿‡ç¨‹åˆ†æ")
        print("=" * 80)
        print(f"Query: {query}\n")

        # æœç´¢
        results = self.rag_client.search(query, limit=limit)

        print(f"è¿”å›ç»“æœæ•°: {len(results)}\n")

        if results:
            for i, result in enumerate(results, 1):
                # è¿‡æ»¤æ‰ None å€¼
                if result is None:
                    continue

                score = result.get("score", 0) if isinstance(result, dict) else 0
                content = result.get("content", "") if isinstance(result, dict) else ""
                metadata = result.get("metadata") if isinstance(result, dict) else None

                # ç¡®ä¿ metadata æ˜¯å­—å…¸
                if metadata is None:
                    metadata = {}
                elif not isinstance(metadata, dict):
                    metadata = {}

                print(f"--- ç»“æœ {i} ---")
                print(f"ç›¸ä¼¼åº¦åˆ†æ•°: {score:.4f}")
                print(f"æ–‡æ¡£ ID: {metadata.get('doc_id', 'N/A')}")
                print(f"æ ‡é¢˜: {metadata.get('title', 'N/A')}")
                print(f"ç‰‡æ®µé•¿åº¦: {len(content)} å­—ç¬¦")
                print(f"å†…å®¹ç‰‡æ®µ: {content[:100]}...")
                print()
        else:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•ç»“æœ\n")

        print("=" * 80 + "\n")

    def chat(
        self,
        platform: str,
        user_id: str,
        user_name: str,
        message: str,
        use_history: bool = True,
        search_limit: int = 3,
        debug: bool = False,
    ) -> str:
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼Œè¿”å›å›å¤

        Args:
            platform: å¹³å°åç§° (bilibili, weibo, etc.)
            user_id: ç”¨æˆ· ID
            user_name: ç”¨æˆ·å
            message: ç”¨æˆ·æ¶ˆæ¯
            use_history: æ˜¯å¦ä½¿ç”¨å¯¹è¯å†å²
            search_limit: æœç´¢ç»“æœé™åˆ¶

        Returns:
            LLM çš„å›å¤
        """
        logger.info(f"[{platform}/{user_id}] æ”¶åˆ°æ¶ˆæ¯: {message[:50]}...")

        # è°ƒè¯•æ¨¡å¼
        if debug:
            self.debug_search(message, limit=search_limit)

        # 1. RAG æœç´¢ç›¸å…³æ–‡æ¡£
        try:
            # ç¡®ä¿æ–‡æœ¬ç¼–ç æ­£ç¡®
            if isinstance(message, bytes):
                message = message.decode('utf-8')
            search_results = self.rag_client.search(message, limit=search_limit)
            context = [result["content"] for result in search_results]

            # è¾“å‡ºè°ƒè¯•ä¿¡æ¯
            if debug:
                print(f"ğŸ“Š æœç´¢ç»Ÿè®¡:")
                print(f"  - è¿”å›ç‰‡æ®µæ•°: {len(search_results)}")
                if search_results:
                    avg_score = sum(r.get("score", 0) for r in search_results) / len(search_results)
                    print(f"  - å¹³å‡ç›¸ä¼¼åº¦: {avg_score:.4f}")
                print()
        except Exception as e:
            logger.warning(f"æœç´¢å¤±è´¥: {e}")
            context = []

        if not context:
            logger.warning(f"æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
            context = ["ï¼ˆæœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼‰"]

        # 2. åŠ è½½å¯¹è¯å†å²
        history = []
        if use_history:
            history = self.conversation_mgr.get_latest_messages(
                platform, user_id, limit=5
            )
            logger.info(f"åŠ è½½ {len(history)} æ¡å†å²è®°å½•")

        # 3. è°ƒç”¨ LLM ç”Ÿæˆå›ç­”
        try:
            if history:
                # æœ‰å†å² - ä½¿ç”¨å¤šè½®å¯¹è¯
                reply = self.llm.generate_with_history(
                    query=message,
                    context=context,
                    history=history,
                )
            else:
                # æ— å†å² - å•è½®å¯¹è¯
                reply = self.llm.generate(
                    query=message,
                    context=context,
                )

            logger.info(f"âœ… ç”Ÿæˆå›ç­”: {reply[:50]}...")
        except Exception as e:
            logger.error(f"LLM è°ƒç”¨å¤±è´¥: {e}")
            reply = f"æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‡ºç°é”™è¯¯: {str(e)}"

        # 4. ä¿å­˜åˆ°å†å²
        try:
            self.conversation_mgr.add_message(
                platform=platform,
                user_id=user_id,
                role="user",
                content=message,
            )
            self.conversation_mgr.add_message(
                platform=platform,
                user_id=user_id,
                role="assistant",
                content=reply,
            )
            logger.info(f"âœ… å†å²å·²ä¿å­˜")
        except Exception as e:
            logger.error(f"ä¿å­˜å†å²å¤±è´¥: {e}")

        return reply

    def get_stats(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        rag_stats = self.rag_client.get_stats()
        return {
            **rag_stats,
            "llm_provider": self.llm.__class__.__name__,
            "service": "RAGChatService",
        }

    def clear_user_history(self, platform: str, user_id: str) -> None:
        """æ¸…ç©ºç”¨æˆ·çš„å¯¹è¯å†å²"""
        self.conversation_mgr.clear_history(platform, user_id)
        logger.info(f"å·²æ¸…ç©º {platform}/{user_id} çš„å¯¹è¯å†å²")
